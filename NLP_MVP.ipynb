{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data treatment"
      ],
      "metadata": {
        "id": "UfbnI-QXpk2J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "dYtDkhyxqINa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50b532b0",
        "outputId": "954c8553-a3b4-4042-a8e0-36faf33826ba"
      },
      "source": [
        "%pip install gensim"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from gensim.models import Word2Vec\n"
      ],
      "metadata": {
        "id": "nrscNAEWqLBo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Raw data scraping, mining, extracting"
      ],
      "metadata": {
        "id": "qSd7YFB3qNIT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data scraping"
      ],
      "metadata": {
        "id": "OmFGQ1IAsdg1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data mining"
      ],
      "metadata": {
        "id": "1yPu7doYsic-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data extracting"
      ],
      "metadata": {
        "id": "9oagaYwOsk48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pure data initialization"
      ],
      "metadata": {
        "id": "jpdqASbjqby2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data\n",
        "data = {\n",
        "    'text': [\"This is a positive review.\", \"This is a negative review.\", \"Another positive example.\", \"Another negative example.\"],\n",
        "    'sentiment': [1, 0, 1, 0] # 1 for positive, 0 for negative\n",
        "}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "u0wmTOO0qoo6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization"
      ],
      "metadata": {
        "id": "x2zPSihuq_kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.fit_on_texts(df['text'])\n",
        "sequences = tokenizer.texts_to_sequences(df['text'])\n"
      ],
      "metadata": {
        "id": "nYF8XtQZrKtX"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Padding sequences"
      ],
      "metadata": {
        "id": "tSrfoSJkrMSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Padding sequences\n",
        "lengths = []\n",
        "for x in sequences:\n",
        "  lengths.append(len(x))\n",
        "\n",
        "max_length = max(lengths)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post', truncating='post')\n"
      ],
      "metadata": {
        "id": "tyoLFtIKrPf4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding"
      ],
      "metadata": {
        "id": "eqyU9mwZrSHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sentences = []\n",
        "for text in df['text']:\n",
        "  sentences.append(text.split())\n",
        "\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((1000, 100)) # 1000 is num_words, 100 is vector_size\n",
        "for i in range(len(tokenizer.word_index.items())):\n",
        "    word = (list(tokenizer.word_index.items()))[i]\n",
        "    if i < 1000:\n",
        "        if word in word2vec_model.wv:\n",
        "            embedding_matrix[i] = word2vec_model.wv[word]\n",
        "\n"
      ],
      "metadata": {
        "id": "7BjH8r58rYR2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "8iqNRWQ1rbUY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX3_G0tzlVtw",
        "outputId": "79169133-b086-46a5-a875-eb2364528d8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 2/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 3/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 4/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 5/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 6/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 7/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 8/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 9/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5000 - loss: 0.6931\n",
            "Epoch 10/10\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5000 - loss: 0.6931\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x781c8c0eda00>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# LSTM\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=1000, output_dim=100, input_length=max_length, weights=[embedding_matrix], trainable=False))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(1, activation='sigmoid')) # Using sigmoid for binary classification\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Labels\n",
        "labels = np.array(df['sentiment'])\n",
        "\n",
        "model.fit(padded_sequences, labels, epochs=10, verbose=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction : evaluate, test, ..."
      ],
      "metadata": {
        "id": "hMwjE6yqrmsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "new_text = [\"This is a great movie!\"]\n",
        "new_sequence = tokenizer.texts_to_sequences(new_text)\n",
        "new_padded_sequence = pad_sequences(new_sequence, maxlen=max_length, padding='post', truncating='post')\n",
        "prediction = model.predict(new_padded_sequence)\n",
        "print(prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtWb5byLrpiG",
        "outputId": "8bda30a3-176a-4d30-aee1-5356abb4b133"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step\n",
            "[[0.5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Web implementation"
      ],
      "metadata": {
        "id": "Yka-AIiEs6nm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download model (.keras, .h5)"
      ],
      "metadata": {
        "id": "c71cvq4XtKqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.keras\")"
      ],
      "metadata": {
        "id": "FO6Cjj5utRG6"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation Frontend"
      ],
      "metadata": {
        "id": "qnNJfNaytWH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow Javascript"
      ],
      "metadata": {
        "id": "gCJKWbO_tovJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "HTML/CSS/JAVASCRIPT\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "l78nok9stdpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementation Backend"
      ],
      "metadata": {
        "id": "VvqqaGONtyjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation Node.js (javascript's backend)"
      ],
      "metadata": {
        "id": "RFEZT3batiAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation cURL (PHP terminal)"
      ],
      "metadata": {
        "id": "y1xtvT8Tt3I1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation ..."
      ],
      "metadata": {
        "id": "awRmlIojuFDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Mobile App implementation"
      ],
      "metadata": {
        "id": "ndo3BuTMucv1"
      }
    }
  ]
}